{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac5eaa32",
   "metadata": {},
   "source": [
    "#  Scaden-methylation Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6457ee-4b3a-4ea1-90df-190264aca1e6",
   "metadata": {},
   "source": [
    "## scMethyl Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9935fabf-a638-4de2-9daa-3dde6cb0aa31",
   "metadata": {},
   "source": [
    "Before we can start using the pipeline, the scaden pipeline has 2 required parts:\n",
    "- A scMethyl-seq dataset (or a methylation array to simulate a dataset).\n",
    "- A testing file that we want to perform deconvolution on.\n",
    "\n",
    "There may be other required files, depending on which steps of the pipeline we want to run.\n",
    "\n",
    "The methylation dataset can be supplied in two ways:\n",
    "- If we want to use a scMethyl-seq dataset, it should be formatted like the [original scaden](https://scaden.readthedocs.io/en/latest/usage.html#bulk-simulation). \n",
    "- If we want to use a methylation array, we can a script to simulate a scMethyl-seq dataset with the proper formatting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a8c3a9",
   "metadata": {},
   "source": [
    "### Generating a data set from a methylation array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a557226f-b2f4-49af-bc3c-d9c2b0738275",
   "metadata": {},
   "source": [
    "We are starting with a methylation array for various leukocytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0b0ab9b-ecc8-4b9e-b2ad-0a7ecf155106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBas\tBmem\tBn\tCD4mem\tCD4nv\tTem\tTn\tEOS\tMono\tNeu\tNK\tTreg\n",
      "cg23788058\t0.796\t0.919\t0.94\t0.869\t0.285\t0.897\t0.693\t0.437\t0.949\t0.919\t0.94\t0.9\n",
      "cg21091766\t0.672\t0.688\t0.858\t0.874\t0.936\t0.458\t0.322\t0.583\t0.811\t0.697\t0.739\t0.872\n",
      "cg16596052\t0.886\t0.876\t0.888\t0.833\t0.591\t0.826\t0.116\t0.901\t0.936\t0.914\t0.922\t0.858\n",
      "cg21782213\t0.931\t0.942\t0.945\t0.828\t0.314\t0.935\t0.934\t0.943\t0.953\t0.953\t0.949\t0.919\n",
      "cg15213052\t0.952\t0.947\t0.949\t0.939\t0.891\t0.935\t0.346\t0.96\t0.968\t0.965\t0.841\t0.949\n",
      "cg17458390\t0.073\t0.101\t0.077\t0.068\t0.184\t0.114\t0.692\t0.06\t0.055\t0.051\t0.072\t0.077\n",
      "cg19850895\t0.946\t0.914\t0.94\t0.925\t0.934\t0.869\t0.426\t0.929\t0.96\t0.924\t0.908\t0.946\n",
      "cg27225309\t0.079\t0.922\t0.585\t0.748\t0.266\t0.518\t0.347\t0.071\t0.351\t0.29\t0.186\t0.179\n",
      "cg17518643\t0.941\t0.947\t0.954\t0.581\t0.245\t0.887\t0.791\t0.583\t0.929\t0.909\t0.91\t0.719\n",
      "cg12043508\t0.79\t0.771\t0.881\t0.909\t0.916\t0.881\t0.453\t0.833\t0.823\t0.802\t0.724\t0.923\n",
      "cg20813776\t0.94\t0.925\t0.931\t0.89\t0.937\t0.386\t0.91\t0.929\t0.937\t0.923\t0.848\t0.924\n",
      "cg00267793\t0.149\t0.927\t0.921\t0.916\t0.92\t0.921\t0.92\t0.921\t0.939\t0.937\t0.933\t0.9\n",
      "cg17491554\t0.918\t0.061\t0.849\t0.793\t0.943\t0.772\t0.941\t0.946\t0.941\t0.948\t0.903\t0.812\n",
      "cg02053685\t0.893\t0.865\t0.875\t0.848\t0.816\t0.907\t0.477\t0.936\t0.933\t0.924\t0.726\t0.936\n",
      "cg08662013\t0.954\t0.896\t0.959\t0.775\t0.507\t0.896\t0.945\t0.952\t0.968\t0.959\t0.944\t0.859\n",
      "cg05202121\t0.879\t0.856\t0.872\t0.844\t0.832\t0.807\t0.805\t0.115\t0.784\t0.658\t0.861\t0.734\n",
      "cg11266582\t0.748\t0.8\t0.753\t0.679\t0.697\t0.714\t0.691\t0.064\t0.821\t0.731\t0.808\t0.635\n",
      "cg07133479\t0.789\t0.862\t0.948\t0.533\t0.248\t0.75\t0.738\t0.531\t0.92\t0.891\t0.866\t0.581\n",
      "cg07495335\t0.959\t0.953\t0.955\t0.503\t0.309\t0.816\t0.673\t0.959\t0.972\t0.967\t0.968\t0.861\n"
     ]
    }
   ],
   "source": [
    "!head -n 20 ~/example/sig.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d32b1d0-8728-45bd-b0d6-7e4a427a2124",
   "metadata": {},
   "source": [
    "We can simulate a scMethyl-seq dataset by sampling from this array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "759ca2e8-2176-446e-86e6-48c047cc8db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created files '~/example/data_counts.txt' and '~/example/data_celltypes.txt'\n"
     ]
    }
   ],
   "source": [
    "!python ~/array_to_sc.py -s 100 -r 2 -o '~/example/data' ~/example/sig.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc004cbc-73ee-4c41-81a3-4fb938db9dea",
   "metadata": {},
   "source": [
    "This script samples each value in the table from a binomial distribution with 1 trial and uses the value as the probability.\n",
    "The number of successes (0 or 1) is used as the corresponding value in the scMethyl-seq dataset.\n",
    "The arguments used are:\n",
    "- `-r`: By setting this to 2, we sampled each cell type 2 times. Higher values generally give better results.\n",
    "- `-s`: Numpy random generator seed for reproducibility.\n",
    "- `-o`: Set the name and location of the output files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a237a15-5def-49a9-9b3e-cf51091bc085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Celltype\n",
      "Bas\n",
      "Bas\n",
      "Bmem\n",
      "Bmem\n",
      "Bn\n",
      "Bn\n",
      "CD4mem\n",
      "CD4mem\n",
      "CD4nv\n",
      "CD4nv\n",
      "Tem\n",
      "Tem\n",
      "Tn\n",
      "Tn\n",
      "EOS\n",
      "EOS\n",
      "Mono\n",
      "Mono\n",
      "Neu\n",
      "Neu\n",
      "NK\n",
      "NK\n",
      "Treg\n",
      "Treg\n"
     ]
    }
   ],
   "source": [
    "# Celltype labels file. Each cell type was sampled twice.\n",
    "!cat ~/example/data_celltypes.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8f27038-2f76-4b69-b74d-e1015fab537e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tcg23788058\tcg21091766\tcg16596052\tcg21782213\tcg15213052\tcg17458390\tcg19850895\tcg27225309\tcg17518643\n",
      "0\t0\t0\t1\t1\t1\t0\t1\t0\t1\n",
      "1\t1\t0\t1\t1\t1\t0\t1\t0\t1\n",
      "2\t1\t0\t1\t1\t1\t0\t1\t1\t1\n",
      "3\t1\t1\t1\t1\t0\t1\t1\t0\t1\n",
      "4\t0\t1\t1\t1\t1\t0\t1\t1\t1\n",
      "5\t1\t1\t1\t1\t1\t0\t1\t1\t1\n",
      "6\t1\t1\t1\t1\t1\t0\t1\t1\t1\n",
      "7\t0\t1\t1\t1\t1\t0\t1\t0\t0\n",
      "8\t0\t1\t0\t1\t1\t0\t1\t1\t0\n",
      "9\t0\t1\t1\t0\t1\t0\t1\t0\t0\n",
      "10\t0\t0\t1\t1\t1\t0\t0\t1\t1\n",
      "11\t1\t1\t1\t1\t1\t0\t1\t0\t1\n",
      "12\t1\t0\t0\t1\t1\t1\t0\t1\t1\n",
      "13\t1\t0\t0\t1\t1\t1\t1\t1\t1\n",
      "14\t1\t1\t1\t1\t1\t0\t1\t0\t0\n",
      "15\t0\t1\t1\t1\t1\t0\t1\t0\t1\n",
      "16\t0\t0\t1\t1\t1\t1\t1\t0\t1\n",
      "17\t1\t1\t1\t1\t1\t0\t1\t0\t1\n",
      "18\t1\t1\t1\t0\t1\t0\t1\t0\t1\n",
      "19\t1\t0\t1\t1\t1\t0\t1\t1\t1\n",
      "20\t0\t1\t1\t1\t1\t0\t1\t0\t1\n",
      "21\t0\t1\t1\t1\t0\t0\t1\t0\t1\n",
      "22\t1\t1\t1\t0\t0\t0\t1\t0\t1\n",
      "23\t1\t0\t1\t1\t1\t0\t1\t0\t1\n"
     ]
    }
   ],
   "source": [
    "# scMethyl-seq file, first 10 columns\n",
    "# The order of the cells here matches the order of the labels in the data_celltypes.txt file\n",
    "!cut -f 1-10 ~/example/data_counts.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da7b4aa-3af6-44b6-982d-a996816aebfc",
   "metadata": {},
   "source": [
    "## Using the pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0de59279-d825-452d-b4b8-95d0dd2c9487",
   "metadata": {},
   "source": [
    "There are 5 steps in the pipeline:\n",
    "1. Simulate training data from sc dataset\n",
    "2. Preprocess training data\n",
    "3. Train model\n",
    "4. Predict on testing data\n",
    "5. Evaluate predictions\n",
    "\n",
    "Each step has its own set of parameters that we'll explain below. \n",
    "To run the pipeline:\n",
    "- Save the parameters to a YAML file, then run `python main.py --load params.yaml` (Recommended)\n",
    "- Run `python main.py ...` with all the parameters as a single command."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e073711b-33ec-4c30-861e-def3e833515c",
   "metadata": {},
   "source": [
    "### Pipeline controls and logging"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c8cecad8-e9c3-49eb-8439-b5dc0aa4835e",
   "metadata": {},
   "source": [
    "```\n",
    "  --load TEXT                     Load parameters from a YAML file.\n",
    "  --no_sim                        Skip the creation of simulated training\n",
    "                                  samples if you have already created a\n",
    "                                  training set.\n",
    "  --no_proc                       Skip the preprocessing step if you have\n",
    "                                  already processed the training data. If\n",
    "                                  using this flag, then --proc is required.\n",
    "  --no_pred                       Skip the creation of simulated training\n",
    "                                  samples if you have already created a\n",
    "                                  training set.\n",
    "  --no_eval                       Skip the evaluation of the model\n",
    "                                  predictions.\n",
    "  --config TEXT                   Name of configuration.\n",
    "  -r, --reference TEXT            Name of the scMethyl dataset.\n",
    "```\n",
    "\n",
    "For this example, we will go through all steps of the pipeline, so we don't need any of the `no_X` flags. \n",
    "\n",
    "We can set some parameters for logging purposes. These parameters will appear in the output logs:\n",
    "- We'll name our entire configuration 'example': `--config example`\n",
    "- Our scMethyl-seq dataset will be called '2': `-r 2`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bee5dba-1b14-49e1-a854-cdfb5e2a4a82",
   "metadata": {},
   "source": [
    "### Simulate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2061eeec-fd97-42fe-b880-491a6838ebc5",
   "metadata": {},
   "source": [
    "These parameters are the same as the original scaden.\n",
    "```\n",
    "  -o, --out TEXT                  Directory to store output files in\n",
    "  -d, --data TEXT                 Path to scMethyl-seq dataset(s)\n",
    "  -c, --cells INTEGER             Number of cells per sample [default: 100]\n",
    "  -n, --n_samples INTEGER         Number of samples to simulate [default:\n",
    "                                  1000]\n",
    "  --pattern TEXT                  File pattern to recognize your processed\n",
    "                                  scMethyl-seq count files\n",
    "  -u, --unknown TEXT              Specifiy cell types to merge into the\n",
    "                                  unknown category. Specify this flag for\n",
    "                                  every cell type you want to merge in\n",
    "                                  unknown. [default: unknown]\n",
    "  -p, --prefix TEXT               Prefix to append to training .h5ad file\n",
    "                                  [default: data]\n",
    "  -f, --data_format TEXT          Data format of scMethyl-seq data, can be 'txt'\n",
    "                                  or 'h5ad' [default: 'txt']\n",
    "```\n",
    "\n",
    "Here's what we'll use:\n",
    "- We previously created our scMethyl-seq dataset and stored it in '~/example', so that will be our data directory: `-d ~/example/`\n",
    "- Our simulated training data will be stored in the same directory: `-o ~/example/`\n",
    "- The training set will contain 1000 samples, each composed of 100 cells: `-c 100 -n 1000`\n",
    "- The training set will be named 'example_data.h5ad': `-p example_data`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd581e4b-deef-4ad1-afd8-5ba8a2637489",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2ece58-ddb6-4018-8c86-8885936a1e29",
   "metadata": {},
   "source": [
    "This step will take the training data from the previous step and do two things:\n",
    "1. Filter the dataset for CpGs that are found in both the training and testing data.\n",
    "2. Remove CpGs that have a variance below a specified cutoff.\n",
    "\n",
    "The testing data should be a text file with CpGs in the rows and samples in the columns.\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3844a59f-cc2e-4af1-b457-d30f7a7796eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSM5527895\tGSM5527896\tGSM5527897\tGSM5527898\tGSM5527899\tGSM5527900\tGSM5527901\tGSM5527902\tGSM5527903\tGSM5527904\n",
      "cg00000029\t0.607449765\t0.599892818\t0.586948371\t0.662251888\t0.617919828\t0.5502694\t0.598716073\t0.635111133\t0.628051098\n",
      "cg00000103\t0.870985191\t0.873235077\t0.819141453\t0.869163829\t0.875618429\t0.867616718\t0.884937108\t0.882602813\t0.870008583\n",
      "cg00000109\t0.876637041\t0.906080531\t0.879807632\t0.880013589\t0.884696543\t0.895972737\t0.894113656\t0.898588888\t0.87744091\n",
      "cg00000155\t0.910281129\t0.919300762\t0.903703837\t0.908400048\t0.916790017\t0.916586292\t0.913071893\t0.920179835\t0.910415242\n",
      "cg00000158\t0.943019832\t0.931720128\t0.933009266\t0.934164567\t0.936311936\t0.934337576\t0.93402081\t0.94247987\t0.931961353\n",
      "cg00000165\t0.126424477\t0.097055468\t0.10636477\t0.096476166\t0.112829813\t0.099359629\t0.104591041\t0.120845857\t0.09475253\n",
      "cg00000221\t0.778814475\t0.793399684\t0.758477645\t0.802238179\t0.77771085\t0.809475039\t0.80114129\t0.80530559\t0.795020253\n",
      "cg00000236\t0.885119026\t0.886765395\t0.873180177\t0.857155153\t0.873845184\t0.86456329\t0.828224726\t0.866741807\t0.865724821\n",
      "cg00000289\t0.596545843\t0.667087291\t0.584861367\t0.683017076\t0.632387672\t0.556214283\t0.658533953\t0.656546058\t0.619382508\n"
     ]
    }
   ],
   "source": [
    "!head -n 10 ~/example/testfile.tsv | cut -f 1-10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e585bcc2-6607-4ef6-bd19-0f8dcc2cc729",
   "metadata": {},
   "source": [
    "Now we'll set the parameters, which are the following:\n",
    "```\n",
    "  --pred TEXT                     Bulk data file (i.e. testing set) that we\n",
    "                                  want to perform deconvolution on.\n",
    "  -proc, --processed_path TEXT    Name of the file that the processed data\n",
    "                                  will be saved to. Must end with .h5ad\n",
    "  --var_cutoff FLOAT              Filter out genes with a variance less than\n",
    "                                  the specified cutoff. A low value is\n",
    "                                  recommended, this should only remove genes\n",
    "                                  that are obviously uninformative. [default:\n",
    "                                  0.1]\n",
    "  -sc, --scaling TEXT             Change scaling option for preprocessing the\n",
    "                                  training data. If something other than the\n",
    "                                  provided options is used, then no scaling\n",
    "                                  will be done. [default: fraction] Options:\n",
    "                                  None (No scaling), log / log_min_max (log2,\n",
    "                                  then scale to the range 0,1), frac /\n",
    "                                  fraction (Divide values by the number of\n",
    "                                  cells)\n",
    "```\n",
    "The scaling option has 3 options:\n",
    "- None\n",
    "- log / log_min_max: log2, then scale to the range 0,1. \n",
    "    - This is the default option for RNA-seq data.\n",
    "- frac / fraction: Divide values by the total number of cells. \n",
    "    - This should be used with a simulated scMethyl-seq training set.\n",
    "\n",
    "The parameters that we will use are:\n",
    "- Test set that we want to perform deconvolution on: `--pred ~/example/testfile.tsv`\n",
    "- Fraction scaling, since we are dealing with methylation data: `-sc frac`\n",
    "- We will assume that the CpGs in our basis methylation array are all important, so we don't want to remove any of them: `--var_cutoff 0`\n",
    "\n",
    "If we want to change the name or location of the preprocessed training data, we would set `-proc`. By default, the output will be named 'processed.h5ad' and be in the directory previously specified in `--out`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c200335f-94e3-4f64-a58f-52f18bb168f3",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b72550a-28ca-4c18-8e76-e694b90f93e2",
   "metadata": {},
   "source": [
    "```\n",
    "  --train_datasets TEXT           Comma-separated list of datasets used for\n",
    "                                  training. Uses all by default.\n",
    "  -m, --model_dir TEXT            Path to store the model in\n",
    "  -b, --batch_size INTEGER        Batch size to use for training. [default:\n",
    "                                  128]\n",
    "  -l, --learning_rate FLOAT       Learning rate used for training. [default:\n",
    "                                  0.0001]\n",
    "  --steps INTEGER                 Number of training steps. [default: 5000]\n",
    "  --seed INTEGER                  Set random seed\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6879db4e-db68-48f5-b974-28376d73d5a6",
   "metadata": {},
   "source": [
    "If we skipped the simulation and processing steps because we already had a processed training data set, it must be specified using the `--processed_path` parameter.\n",
    "Otherwise, the pipeline will automatically use the outputs from the previous steps.\n",
    "\n",
    "Now for our parameters:\n",
    "- Our model will be stored in the specified directory: `-m ~/example/model/`\n",
    "- Model training hyperparameters: `-b 256 -l 0.0001 --steps 1000 --seed 100`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d71e3d-44bf-47d7-a762-d4175ac10ed8",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c513ad8-2351-470b-969c-10335a19a930",
   "metadata": {},
   "source": [
    "```\n",
    "  -po, --prediction_outname TEXT  Name of predictions file.\n",
    "  --prediction_scaling TEXT       Change scaling option for the preprocessing\n",
    "                                  done when making predictions. Uses the same\n",
    "                                  options as --scaling.\n",
    "```\n",
    "\n",
    "Uses the trained model on the testing data set to predict the cell type proportions. Outputs results to a text file.\n",
    "\n",
    "Parameters:\n",
    "- Name of the output text file: `-po ~/example/test_predictions.txt`\n",
    "- Scaling to apply to the testing data. If this data is a methylation array, don't use any scaling: `--prediction_scaling None`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bffc25a-b439-4c74-8bf0-19f4f4814f27",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fb828f-db04-4e73-87ae-0850ded3f69d",
   "metadata": {},
   "source": [
    "```\n",
    "  -g, --ground_truth TEXT         Name of file containing the ground truth\n",
    "                                  cell proportions.\n",
    "```\n",
    "Calculate the correlation coefficients between the predictions and a table containing the ground truth proportions.\n",
    "Outputs a json file that shows for each cell type:\n",
    "- The predicted cell type that has the highest correlation\n",
    "- The correlation coefficient\n",
    "- The mean squared error for the the best correlated cell type.\n",
    "\n",
    "Our ground truth proportions file: `-g ~/example/test_proportions.tsv`\n",
    "\n",
    "The ground truth proportions should be a table where the columns are cell types and the rows are samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1a589fe-c57e-42e8-a47e-68b71894d67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bas\tbmem\tbnv\tcd4mem\tcd4nv\tcd8mem\tcd8nv\teos\tmono\tneu\tnk\ttreg\n",
      "GSM5527895\t13.14\t13.26\t6.53\t10.08\t4.47\t10.95\t5.99\t9.01\t6.89\t3.02\t6.36\t10.28\n",
      "GSM5527896\t11.54\t8.6\t6.71\t8.65\t8.14\t9.13\t6.16\t8.62\t3.72\t8.63\t8.43\t11.67\n",
      "GSM5527897\t8.75\t11.12\t3.68\t21.32\t10.16\t11.84\t2.8\t5.05\t3.92\t3.57\t5.14\t12.68\n",
      "GSM5527898\t8.53\t7.2\t18.76\t4.75\t7.9\t9.76\t14.75\t7.05\t5.78\t3.92\t7.35\t4.24\n",
      "GSM5527899\t6.98\t5.22\t5.16\t6.04\t7.61\t8.29\t8.19\t5.12\t8.09\t8.28\t22.23\t8.79\n",
      "GSM5527900\t9.42\t12.49\t7.14\t8.11\t5.07\t4.9\t6.82\t10.43\t4.96\t15.74\t9.71\t5.21\n",
      "GSM5527901\t2.29\t7.85\t6.46\t8.54\t9.55\t9.55\t9.99\t11.26\t13.28\t9.18\t4.52\t7.51\n",
      "GSM5527902\t5.56\t5.37\t7.58\t6.23\t4.18\t5.06\t3.83\t7.97\t10.63\t15.69\t16.92\t10.97\n",
      "GSM5527903\t7.39\t7.84\t11.17\t14.13\t8.38\t6.5\t1.9\t10.29\t6.38\t13.74\t8.2\t4.08\n"
     ]
    }
   ],
   "source": [
    "!head ~/example/test_proportions.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a965991-6400-42dd-b284-b9578196235d",
   "metadata": {},
   "source": [
    "## Putting everything together"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fd31b16d",
   "metadata": {},
   "source": [
    "YAML file `params.yaml':\n",
    "```\n",
    "config: example\n",
    "reference: \"2\"\n",
    "data: ~/example/\n",
    "out: ~/example/\n",
    "cells: 100\n",
    "n_samples: 1000\n",
    "prefix: example_data\n",
    "pred: ~/example/testfile.tsv\n",
    "scaling: frac\n",
    "var_cutoff: 0\n",
    "model_dir: ~/example/model/\n",
    "batch_size: 256\n",
    "learning_rate: 0.0001\n",
    "steps: 1000\n",
    "seed: 100\n",
    "prediction_outname: ~/example/test_predictions.txt\n",
    "prediction_scaling: None\n",
    "ground_truth: ~/example/test_proportions.tsv\n",
    "```\n",
    "\n",
    "Run: `python main.py --load params.yaml`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0b6c2b44-d024-47e4-8294-c07aeba60e0f",
   "metadata": {},
   "source": [
    "Command line only version:\n",
    "```\n",
    "python ~/ceph/scaden/pipeline/main.py \\\n",
    "--config example \\\n",
    "-r 2 \\\n",
    "-d ~/example/ \\\n",
    "-o ~/example/ \\\n",
    "-c 100 \\\n",
    "-n 1000 \\\n",
    "-p example_data \\\n",
    "--pred ~/example/testfile.tsv \\\n",
    "-sc frac \\\n",
    "--var_cutoff 0 \\\n",
    "-m ~/example/model/ \\\n",
    "-b 256 \\\n",
    "-l 0.0001 \\\n",
    "--steps 1000 \\\n",
    "--seed 100 \\\n",
    "-po ~/example/test_predictions.txt \\\n",
    "--prediction_scaling None \\\n",
    "-g ~/example/test_proportions.tsv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7d8706-9f5e-4a08-b720-c898627757ff",
   "metadata": {},
   "source": [
    "## Example Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b47d775-5aa8-4b60-b4e3-2e0440c81926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "     ____                _            \n",
      "    / ___|  ___ __ _  __| | ___ _ __  \n",
      "    \\___ \\ / __/ _` |/ _` |/ _ \\ '_ \\ \n",
      "     ___) | (_| (_| | (_| |  __/ | | |\n",
      "    |____/ \\___\\__,_|\\__,_|\\___|_| |_|\n",
      "    \u001b[0m\n",
      "\u001b[34mINFO    \u001b[0m Datasets: \u001b[1;36m[\u001b[0m\u001b[32m'data'\u001b[0m\u001b[1;36m]\u001b[0m                                 \u001b]8;id=13946;file:///mnt/ceph/users/wkoh1/scaden/pipeline/bulk_simulator.py\u001b\\\u001b[2mbulk_simulator.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=424318;file:///mnt/ceph/users/wkoh1/scaden/pipeline/bulk_simulator.py#84\u001b\\\u001b[2m84\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[34mINFO    \u001b[0m \u001b[1;4mSimulating data from data\u001b[0m                          \u001b]8;id=665277;file:///mnt/ceph/users/wkoh1/scaden/pipeline/bulk_simulator.py\u001b\\\u001b[2mbulk_simulator.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=884037;file:///mnt/ceph/users/wkoh1/scaden/pipeline/bulk_simulator.py#89\u001b\\\u001b[2m89\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[34mINFO    \u001b[0m Loading \u001b[36mdata\u001b[0m dataset \u001b[33m...\u001b[0m                          \u001b]8;id=909606;file:///mnt/ceph/users/wkoh1/scaden/pipeline/bulk_simulator.py\u001b\\\u001b[2mbulk_simulator.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=463442;file:///mnt/ceph/users/wkoh1/scaden/pipeline/bulk_simulator.py#141\u001b\\\u001b[2m141\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[34mINFO    \u001b[0m Merging unknown cell types: \u001b[1m[\u001b[0m\u001b[32m'unknown'\u001b[0m\u001b[1m]\u001b[0m           \u001b]8;id=419849;file:///mnt/ceph/users/wkoh1/scaden/pipeline/bulk_simulator.py\u001b\\\u001b[2mbulk_simulator.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=210977;file:///mnt/ceph/users/wkoh1/scaden/pipeline/bulk_simulator.py#107\u001b\\\u001b[2m107\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[34mINFO    \u001b[0m Subsampling \u001b[1;36mdata\u001b[0m \u001b[33m...\u001b[0m                              \u001b]8;id=702438;file:///mnt/ceph/users/wkoh1/scaden/pipeline/bulk_simulator.py\u001b\\\u001b[2mbulk_simulator.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=178781;file:///mnt/ceph/users/wkoh1/scaden/pipeline/bulk_simulator.py#110\u001b\\\u001b[2m110\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2K\u001b[1;34mNormal samples\u001b[0m \u001b[1;36m0\u001b[0m \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1;34mNormal samples\u001b[0m \u001b[1;36m5\u001b[0m \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n",
      "\u001b[1;34mSparse samples\u001b[0m \u001b[1;36m5\u001b[0m \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n",
      "\u001b[?25h/mnt/home/wkoh1/venv/scaden/lib/python3.9/site-packages/anndata/_core/anndata.py:121: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n",
      "... storing 'ds' as categorical\n",
      "\u001b[34mINFO    \u001b[0m \u001b[1;32mFinished data simulation!\u001b[0m                          \u001b]8;id=677066;file:///mnt/ceph/users/wkoh1/scaden/pipeline/bulk_simulator.py\u001b\\\u001b[2mbulk_simulator.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=626644;file:///mnt/ceph/users/wkoh1/scaden/pipeline/bulk_simulator.py#92\u001b\\\u001b[2m92\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[34mINFO    \u001b[0m Merging datasets:                                 \u001b]8;id=202459;file:///mnt/ceph/users/wkoh1/scaden/pipeline/bulk_simulator.py\u001b\\\u001b[2mbulk_simulator.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=832530;file:///mnt/ceph/users/wkoh1/scaden/pipeline/bulk_simulator.py#327\u001b\\\u001b[2m327\u001b[0m\u001b]8;;\u001b\\\n",
      "         \u001b[1m[\u001b[0m\u001b[32m'/mnt/home/wkoh1/example/data.h5ad'\u001b[0m\u001b[1m]\u001b[0m into        \u001b[2m                     \u001b[0m\n",
      "         \u001b[1;36mexample_data.h5ad\u001b[0m                                 \u001b[2m                     \u001b[0m\n",
      "\u001b[34mINFO    \u001b[0m Pre-processing raw data \u001b[33m...\u001b[0m                               \u001b]8;id=213585;file:///mnt/ceph/users/wkoh1/scaden/pipeline/process.py\u001b\\\u001b[2mprocess.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=511591;file:///mnt/ceph/users/wkoh1/scaden/pipeline/process.py#76\u001b\\\u001b[2m76\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[34mINFO    \u001b[0m Subsetting genes \u001b[33m...\u001b[0m                                      \u001b]8;id=594401;file:///mnt/ceph/users/wkoh1/scaden/pipeline/process.py\u001b\\\u001b[2mprocess.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=686961;file:///mnt/ceph/users/wkoh1/scaden/pipeline/process.py#80\u001b\\\u001b[2m80\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[34mINFO    \u001b[0m Scaling using frac                                        \u001b]8;id=526843;file:///mnt/ceph/users/wkoh1/scaden/pipeline/process.py\u001b\\\u001b[2mprocess.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=213700;file:///mnt/ceph/users/wkoh1/scaden/pipeline/process.py#84\u001b\\\u001b[2m84\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[34mINFO    \u001b[0m Writing to disk \u001b[33m...\u001b[0m                                       \u001b]8;id=218614;file:///mnt/ceph/users/wkoh1/scaden/pipeline/process.py\u001b\\\u001b[2mprocess.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=633787;file:///mnt/ceph/users/wkoh1/scaden/pipeline/process.py#93\u001b\\\u001b[2m93\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[34mINFO    \u001b[0m Data pre-processing done.                                 \u001b]8;id=322823;file:///mnt/ceph/users/wkoh1/scaden/pipeline/process.py\u001b\\\u001b[2mprocess.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=855927;file:///mnt/ceph/users/wkoh1/scaden/pipeline/process.py#95\u001b\\\u001b[2m95\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[34mINFO    \u001b[0m Created processed file:                                   \u001b]8;id=883544;file:///mnt/ceph/users/wkoh1/scaden/pipeline/process.py\u001b\\\u001b[2mprocess.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=338750;file:///mnt/ceph/users/wkoh1/scaden/pipeline/process.py#96\u001b\\\u001b[2m96\u001b[0m\u001b]8;;\u001b\\\n",
      "         \u001b[35m/mnt/home/wkoh1/example/\u001b[0m\u001b[95mprocessed.h5ad\u001b[0m                    \u001b[2m             \u001b[0m\n",
      "\u001b[34mINFO    \u001b[0m \u001b[36mTraining M256 Model \u001b[0m\u001b[33m...\u001b[0m\u001b[36m \u001b[0m                                    \u001b]8;id=624198;file:///mnt/ceph/users/wkoh1/scaden/pipeline/train.py\u001b\\\u001b[2mtrain.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=487290;file:///mnt/ceph/users/wkoh1/scaden/pipeline/train.py#56\u001b\\\u001b[2m56\u001b[0m\u001b]8;;\u001b\\\n",
      "2023-03-24 18:11:18.324255: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "\u001b[2K\u001b[1;34mm256\u001b[0m \u001b[1;36mStep: 9, Loss: 0.0130\u001b[0m \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m━━━━━━━━━━━━━━\u001b[0m\n",
      "\u001b[?25h\u001b[31mWARNING \u001b[0m Compiled the loaded model, but the compiled metrics \u001b]8;id=822908;file:///mnt/home/wkoh1/venv/scaden/lib/python3.9/site-packages/keras/saving/legacy/saving_utils.py\u001b\\\u001b[2msaving_utils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=804510;file:///mnt/home/wkoh1/venv/scaden/lib/python3.9/site-packages/keras/saving/legacy/saving_utils.py#359\u001b\\\u001b[2m359\u001b[0m\u001b]8;;\u001b\\\n",
      "         have yet to be built. `model.compile_metrics` will  \u001b[2m                   \u001b[0m\n",
      "         be empty until you train or evaluate the model.     \u001b[2m                   \u001b[0m\n",
      "\u001b[34mINFO    \u001b[0m Assets written to:                                  \u001b]8;id=914799;file:///mnt/home/wkoh1/venv/scaden/lib/python3.9/site-packages/tensorflow/python/saved_model/builder_impl.py\u001b\\\u001b[2mbuilder_impl.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=353956;file:///mnt/home/wkoh1/venv/scaden/lib/python3.9/site-packages/tensorflow/python/saved_model/builder_impl.py#797\u001b\\\u001b[2m797\u001b[0m\u001b]8;;\u001b\\\n",
      "         \u001b[35m/mnt/home/wkoh1/example/model/\u001b[0m\u001b[35m/m256/\u001b[0m\u001b[95massets\u001b[0m          \u001b[2m                   \u001b[0m\n",
      "\u001b[34mINFO    \u001b[0m \u001b[36mTraining M512 Model \u001b[0m\u001b[33m...\u001b[0m\u001b[36m \u001b[0m                                    \u001b]8;id=152639;file:///mnt/ceph/users/wkoh1/scaden/pipeline/train.py\u001b\\\u001b[2mtrain.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=606191;file:///mnt/ceph/users/wkoh1/scaden/pipeline/train.py#71\u001b\\\u001b[2m71\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2K\u001b[1;34mm512\u001b[0m \u001b[1;36mStep: 9, Loss: 0.0117\u001b[0m \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[0m\u001b[90m━━━━━\u001b[0m\n",
      "\u001b[?25h\u001b[31mWARNING \u001b[0m Compiled the loaded model, but the compiled metrics \u001b]8;id=853928;file:///mnt/home/wkoh1/venv/scaden/lib/python3.9/site-packages/keras/saving/legacy/saving_utils.py\u001b\\\u001b[2msaving_utils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=163354;file:///mnt/home/wkoh1/venv/scaden/lib/python3.9/site-packages/keras/saving/legacy/saving_utils.py#359\u001b\\\u001b[2m359\u001b[0m\u001b]8;;\u001b\\\n",
      "         have yet to be built. `model.compile_metrics` will  \u001b[2m                   \u001b[0m\n",
      "         be empty until you train or evaluate the model.     \u001b[2m                   \u001b[0m\n",
      "\u001b[34mINFO    \u001b[0m Assets written to:                                  \u001b]8;id=989340;file:///mnt/home/wkoh1/venv/scaden/lib/python3.9/site-packages/tensorflow/python/saved_model/builder_impl.py\u001b\\\u001b[2mbuilder_impl.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=954419;file:///mnt/home/wkoh1/venv/scaden/lib/python3.9/site-packages/tensorflow/python/saved_model/builder_impl.py#797\u001b\\\u001b[2m797\u001b[0m\u001b]8;;\u001b\\\n",
      "         \u001b[35m/mnt/home/wkoh1/example/model/\u001b[0m\u001b[35m/m512/\u001b[0m\u001b[95massets\u001b[0m          \u001b[2m                   \u001b[0m\n",
      "\u001b[34mINFO    \u001b[0m \u001b[36mTraining M1024 Model \u001b[0m\u001b[33m...\u001b[0m\u001b[36m \u001b[0m                                   \u001b]8;id=598611;file:///mnt/ceph/users/wkoh1/scaden/pipeline/train.py\u001b\\\u001b[2mtrain.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=244805;file:///mnt/ceph/users/wkoh1/scaden/pipeline/train.py#86\u001b\\\u001b[2m86\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2K\u001b[1;34mm1024\u001b[0m \u001b[1;36mStep: 9, Loss: 0.0073\u001b[0m \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[0m\u001b[90m━━━━━\u001b[0m\n",
      "\u001b[?25h\u001b[31mWARNING \u001b[0m Compiled the loaded model, but the compiled metrics \u001b]8;id=89960;file:///mnt/home/wkoh1/venv/scaden/lib/python3.9/site-packages/keras/saving/legacy/saving_utils.py\u001b\\\u001b[2msaving_utils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=273834;file:///mnt/home/wkoh1/venv/scaden/lib/python3.9/site-packages/keras/saving/legacy/saving_utils.py#359\u001b\\\u001b[2m359\u001b[0m\u001b]8;;\u001b\\\n",
      "         have yet to be built. `model.compile_metrics` will  \u001b[2m                   \u001b[0m\n",
      "         be empty until you train or evaluate the model.     \u001b[2m                   \u001b[0m\n",
      "\u001b[34mINFO    \u001b[0m Assets written to:                                  \u001b]8;id=189672;file:///mnt/home/wkoh1/venv/scaden/lib/python3.9/site-packages/tensorflow/python/saved_model/builder_impl.py\u001b\\\u001b[2mbuilder_impl.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=431643;file:///mnt/home/wkoh1/venv/scaden/lib/python3.9/site-packages/tensorflow/python/saved_model/builder_impl.py#797\u001b\\\u001b[2m797\u001b[0m\u001b]8;;\u001b\\\n",
      "         \u001b[35m/mnt/home/wkoh1/example/model/\u001b[0m\u001b[35m/m1024/\u001b[0m\u001b[95massets\u001b[0m         \u001b[2m                   \u001b[0m\n",
      "\u001b[34mINFO    \u001b[0m \u001b[32mTraining finished.\u001b[0m                                         \u001b]8;id=521433;file:///mnt/ceph/users/wkoh1/scaden/pipeline/train.py\u001b\\\u001b[2mtrain.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=674593;file:///mnt/ceph/users/wkoh1/scaden/pipeline/train.py#100\u001b\\\u001b[2m100\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[34mINFO    \u001b[0m \u001b[1mTraining time: \u001b[0m\u001b[1;36m5.242\u001b[0m                                        \u001b]8;id=386894;file:///mnt/ceph/users/wkoh1/scaden/pipeline/main.py\u001b\\\u001b[2mmain.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=893837;file:///mnt/ceph/users/wkoh1/scaden/pipeline/main.py#164\u001b\\\u001b[2m164\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[34mINFO    \u001b[0m \u001b[1mCreated config file: \u001b[0m                                       \u001b]8;id=237782;file:///mnt/ceph/users/wkoh1/scaden/pipeline/main.py\u001b\\\u001b[2mmain.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=494326;file:///mnt/ceph/users/wkoh1/scaden/pipeline/main.py#187\u001b\\\u001b[2m187\u001b[0m\u001b]8;;\u001b\\\n",
      "         \u001b[1;35m/mnt/home/wkoh1/example/\u001b[0m\u001b[1;95mconfig_example.json\u001b[0m                 \u001b[2m           \u001b[0m\n",
      "\u001b[34mINFO    \u001b[0m Loaded pre-trained model: \u001b[36mm256\u001b[0m                      \u001b]8;id=820087;file:///mnt/ceph/users/wkoh1/scaden/pipeline/class_scaden.py\u001b\\\u001b[2mclass_scaden.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=692850;file:///mnt/ceph/users/wkoh1/scaden/pipeline/class_scaden.py#307\u001b\\\u001b[2m307\u001b[0m\u001b]8;;\u001b\\\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "\u001b[34mINFO    \u001b[0m Loaded pre-trained model: \u001b[36mm512\u001b[0m                      \u001b]8;id=489756;file:///mnt/ceph/users/wkoh1/scaden/pipeline/class_scaden.py\u001b\\\u001b[2mclass_scaden.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=106923;file:///mnt/ceph/users/wkoh1/scaden/pipeline/class_scaden.py#307\u001b\\\u001b[2m307\u001b[0m\u001b]8;;\u001b\\\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "\u001b[34mINFO    \u001b[0m Loaded pre-trained model: \u001b[36mm1024\u001b[0m                     \u001b]8;id=13560;file:///mnt/ceph/users/wkoh1/scaden/pipeline/class_scaden.py\u001b\\\u001b[2mclass_scaden.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=328029;file:///mnt/ceph/users/wkoh1/scaden/pipeline/class_scaden.py#307\u001b\\\u001b[2m307\u001b[0m\u001b]8;;\u001b\\\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "\u001b[34mINFO    \u001b[0m \u001b[1mCreated cell composition predictions: \u001b[0m                    \u001b]8;id=697011;file:///mnt/ceph/users/wkoh1/scaden/pipeline/predict.py\u001b\\\u001b[2mpredict.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=817828;file:///mnt/ceph/users/wkoh1/scaden/pipeline/predict.py#98\u001b\\\u001b[2m98\u001b[0m\u001b]8;;\u001b\\\n",
      "         \u001b[1;35m/mnt/home/wkoh1/example/\u001b[0m\u001b[1;95mtest_predictions.txt\u001b[0m              \u001b[2m             \u001b[0m\n",
      "\u001b[34mINFO    \u001b[0m Evaluating predictions \u001b[33m...\u001b[0m                               \u001b]8;id=764659;file:///mnt/ceph/users/wkoh1/scaden/pipeline/evaluate.py\u001b\\\u001b[2mevaluate.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=285189;file:///mnt/ceph/users/wkoh1/scaden/pipeline/evaluate.py#97\u001b\\\u001b[2m97\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[34mINFO    \u001b[0m \u001b[1mCreated evaluation results: \u001b[0m                            \u001b]8;id=141758;file:///mnt/ceph/users/wkoh1/scaden/pipeline/evaluate.py\u001b\\\u001b[2mevaluate.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=346554;file:///mnt/ceph/users/wkoh1/scaden/pipeline/evaluate.py#107\u001b\\\u001b[2m107\u001b[0m\u001b]8;;\u001b\\\n",
      "         \u001b[1;35m/mnt/home/wkoh1/example/\u001b[0m\u001b[1;95mreport_example.json\u001b[0m             \u001b[2m               \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python ~/ceph/scaden/pipeline/main.py \\\n",
    "--config example \\\n",
    "-r 2 \\\n",
    "-d ~/example/ \\\n",
    "-o ~/example/ \\\n",
    "-c 10 \\\n",
    "-n 10 \\\n",
    "-p example_data \\\n",
    "--pred ~/example/testfile.tsv \\\n",
    "-sc frac \\\n",
    "--var_cutoff 0 \\\n",
    "-m ~/example/model/ \\\n",
    "-b 256 \\\n",
    "-l 0.0001 \\\n",
    "--steps 10 \\\n",
    "--seed 100 \\\n",
    "-po ~/example/test_predictions.txt \\\n",
    "--prediction_scaling None \\\n",
    "-g ~/example/test_proportions.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48265c19",
   "metadata": {},
   "source": [
    "## Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efd53649-852b-43ae-b9f4-61a0be16b597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"config\": \"example\",\n",
      "    \"Data\": {\n",
      "        \"cells\": 10,\n",
      "        \"n_samples\": 10,\n",
      "        \"var_cutoff\": 0.0,\n",
      "        \"scaling\": \"frac\",\n",
      "        \"reference\": \"2\"\n",
      "    },\n",
      "    \"Model\": {\n",
      "        \"seed\": 100,\n",
      "        \"steps\": 10,\n",
      "        \"batch_size\": 256,\n",
      "        \"learning_rate\": 0.0001\n",
      "    }\n",
      "}"
     ]
    }
   ],
   "source": [
    "!cat ~/example/config_example.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfcbdf42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBmem\tBn\tTreg\tTem\tNeu\tBas\tCD4mem\tNK\tEOS\tCD4nv\tMono\tTn\n",
      "GSM5527895\t0.07171733\t0.07502185\t0.15386467\t0.059344903\t0.09296023\t0.08448567\t0.11175108\t0.0778093\t0.061400663\t0.05196402\t0.070394054\t0.08928626\n",
      "GSM5527896\t0.07170308\t0.074799605\t0.153028\t0.05922353\t0.09196025\t0.08494222\t0.112300724\t0.078326605\t0.061703008\t0.05181678\t0.06985539\t0.09034077\n",
      "GSM5527897\t0.07122642\t0.0754433\t0.15398496\t0.059601083\t0.09217551\t0.084852464\t0.11120849\t0.07761336\t0.060960066\t0.05226658\t0.070305645\t0.09036214\n",
      "GSM5527898\t0.07276497\t0.07571867\t0.15080571\t0.059996516\t0.09227895\t0.08445265\t0.11158631\t0.07735372\t0.061546028\t0.0517415\t0.070803374\t0.0909515\n",
      "GSM5527899\t0.07172493\t0.07515318\t0.1512052\t0.059090838\t0.09252611\t0.084445596\t0.11313233\t0.07786428\t0.061798204\t0.0514541\t0.06993266\t0.09167254\n",
      "GSM5527900\t0.07279977\t0.07573294\t0.14927585\t0.059624087\t0.09240439\t0.08528351\t0.1124446\t0.078572996\t0.062028453\t0.05163589\t0.070032366\t0.09016514\n",
      "GSM5527901\t0.07229191\t0.07469981\t0.15142314\t0.059523374\t0.09278536\t0.085699596\t0.111552514\t0.07766864\t0.061894506\t0.051647756\t0.07082814\t0.08998526\n",
      "GSM5527902\t0.072436556\t0.074700534\t0.15089937\t0.059433836\t0.09252723\t0.085038304\t0.11268254\t0.078076385\t0.062454224\t0.051541913\t0.069746554\t0.09046254\n",
      "GSM5527903\t0.07183893\t0.0746832\t0.1520031\t0.05967018\t0.09248853\t0.084786035\t0.11169493\t0.07884532\t0.06224982\t0.05169766\t0.07000316\t0.09003914\n",
      "GSM5527904\t0.072850086\t0.0753961\t0.1512329\t0.059299916\t0.092594974\t0.084519744\t0.11280081\t0.078229986\t0.06173132\t0.051129606\t0.0704548\t0.089759745\n",
      "GSM5527905\t0.07223467\t0.07536974\t0.15202427\t0.059877012\t0.0922293\t0.08420864\t0.11104489\t0.078438826\t0.06154013\t0.051695123\t0.0702951\t0.09104226\n",
      "GSM5527906\t0.073061354\t0.075746305\t0.14797582\t0.05976208\t0.092804275\t0.08599603\t0.11094072\t0.077597566\t0.061911732\t0.051906854\t0.070305735\t0.09199154\n"
     ]
    }
   ],
   "source": [
    "!cat ~/example/test_predictions.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "967a266a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"training_time\": 5.242,\n",
      "    \"results\": {\n",
      "        \"Predictions best correlated celltype\": {\n",
      "            \"bas\": \"Treg\",\n",
      "            \"bmem\": \"CD4nv\",\n",
      "            \"bnv\": \"Tem\",\n",
      "            \"cd4mem\": \"Treg\",\n",
      "            \"cd4nv\": \"Mono\",\n",
      "            \"cd8mem\": \"Mono\",\n",
      "            \"cd8nv\": \"Bmem\",\n",
      "            \"eos\": \"Bas\",\n",
      "            \"mono\": \"Neu\",\n",
      "            \"neu\": \"EOS\",\n",
      "            \"nk\": \"CD4mem\",\n",
      "            \"treg\": \"Treg\"\n",
      "        },\n",
      "        \"Correlation coefficient\": {\n",
      "            \"bas\": 0.5280621173558456,\n",
      "            \"bmem\": 0.5130729943912468,\n",
      "            \"bnv\": 0.7799385639099412,\n",
      "            \"cd4mem\": 0.7123326077212231,\n",
      "            \"cd4nv\": 0.39923386263326455,\n",
      "            \"cd8mem\": 0.4988801132564815,\n",
      "            \"cd8nv\": 0.6983234113218432,\n",
      "            \"eos\": 0.8145635891498426,\n",
      "            \"mono\": 0.6555647976568822,\n",
      "            \"neu\": 0.8893132773658662,\n",
      "            \"nk\": 0.6820642672771092,\n",
      "            \"treg\": 0.6401583289778798\n",
      "        },\n",
      "        \"Mean squared error\": {\n",
      "            \"bas\": 0.00892568938784334,\n",
      "            \"bmem\": 0.001642554992388229,\n",
      "            \"bnv\": 0.002286927440668308,\n",
      "            \"cd4mem\": 0.0056719945627055,\n",
      "            \"cd4nv\": 0.0007815855425045321,\n",
      "            \"cd8mem\": 0.001124594966570214,\n",
      "            \"cd8nv\": 0.0014943523439947337,\n",
      "            \"eos\": 0.000827668709871016,\n",
      "            \"mono\": 0.001070255031710852,\n",
      "            \"neu\": 0.0026601116454590874,\n",
      "            \"nk\": 0.0030791511400248307,\n",
      "            \"treg\": 0.006333756781707553\n",
      "        }\n",
      "    }\n",
      "}"
     ]
    }
   ],
   "source": [
    "!cat ~/example/report_example.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scaden",
   "language": "python",
   "name": "scaden"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
